{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and calls\n",
    "from IPython.display import clear_output\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "from pennylane.templates.embeddings import AmplitudeEmbedding, AngleEmbedding\n",
    "from pennylane.templates.state_preparations import MottonenStatePreparation\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.models import Model\n",
    "from keras import layers, losses\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import autograd.numpy as anp\n",
    "import matplotlib.pyplot as plt\n",
    "global Embedding\n",
    "\n",
    "clear_output()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unitaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different unitary ansatz to test from different papers (Hur el. at provides a comprehensive list of ansatzes in their code.)\n",
    "\n",
    "# Unitary Ansatze for Convolutional Layer\n",
    "def U_TTN(params, wires):  # 2 params\n",
    "    qml.RY(params[0], wires=wires[0])\n",
    "    qml.RY(params[1], wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[0], wires[1]])\n",
    "\n",
    "\n",
    "def U_5(params, wires):  # 10 params\n",
    "    qml.RX(params[0], wires=wires[0])\n",
    "    qml.RX(params[1], wires=wires[1])\n",
    "    qml.RZ(params[2], wires=wires[0])\n",
    "    qml.RZ(params[3], wires=wires[1])\n",
    "    qml.CRZ(params[4], wires=[wires[1], wires[0]])\n",
    "    qml.CRZ(params[5], wires=[wires[0], wires[1]])\n",
    "    qml.RX(params[6], wires=wires[0])\n",
    "    qml.RX(params[7], wires=wires[1])\n",
    "    qml.RZ(params[8], wires=wires[0])\n",
    "    qml.RZ(params[9], wires=wires[1])\n",
    "\n",
    "\n",
    "def U_6(params, wires):  # 10 params\n",
    "    qml.RX(params[0], wires=wires[0])\n",
    "    qml.RX(params[1], wires=wires[1])\n",
    "    qml.RZ(params[2], wires=wires[0])\n",
    "    qml.RZ(params[3], wires=wires[1])\n",
    "    qml.CRX(params[4], wires=[wires[1], wires[0]])\n",
    "    qml.CRX(params[5], wires=[wires[0], wires[1]])\n",
    "    qml.RX(params[6], wires=wires[0])\n",
    "    qml.RX(params[7], wires=wires[1])\n",
    "    qml.RZ(params[8], wires=wires[0])\n",
    "    qml.RZ(params[9], wires=wires[1])\n",
    "\n",
    "\n",
    "def U_9(params, wires):  # 2 params\n",
    "    qml.Hadamard(wires=wires[0])\n",
    "    qml.Hadamard(wires=wires[1])\n",
    "    qml.CZ(wires=[wires[0], wires[1]])\n",
    "    qml.RX(params[0], wires=wires[0])\n",
    "    qml.RX(params[1], wires=wires[1])\n",
    "\n",
    "\n",
    "def U_13(params, wires):  # 6 params\n",
    "    qml.RY(params[0], wires=wires[0])\n",
    "    qml.RY(params[1], wires=wires[1])\n",
    "    qml.CRZ(params[2], wires=[wires[1], wires[0]])\n",
    "    qml.RY(params[3], wires=wires[0])\n",
    "    qml.RY(params[4], wires=wires[1])\n",
    "    qml.CRZ(params[5], wires=[wires[0], wires[1]])\n",
    "\n",
    "\n",
    "def U_14(params, wires):  # 6 params\n",
    "    qml.RY(params[0], wires=wires[0])\n",
    "    qml.RY(params[1], wires=wires[1])\n",
    "    qml.CRX(params[2], wires=[wires[1], wires[0]])\n",
    "    qml.RY(params[3], wires=wires[0])\n",
    "    qml.RY(params[4], wires=wires[1])\n",
    "    qml.CRX(params[5], wires=[wires[0], wires[1]])\n",
    "\n",
    "\n",
    "def U_15(params, wires):  # 4 params\n",
    "    qml.RY(params[0], wires=wires[0])\n",
    "    qml.RY(params[1], wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[1], wires[0]])\n",
    "    qml.RY(params[2], wires=wires[0])\n",
    "    qml.RY(params[3], wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[0], wires[1]])\n",
    "\n",
    "\n",
    "def U_SO4(params, wires):  # 6 params\n",
    "    qml.RY(params[0], wires=wires[0])\n",
    "    qml.RY(params[1], wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[0], wires[1]])\n",
    "    qml.RY(params[2], wires=wires[0])\n",
    "    qml.RY(params[3], wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[0], wires[1]])\n",
    "    qml.RY(params[4], wires=wires[0])\n",
    "    qml.RY(params[5], wires=wires[1])\n",
    "\n",
    "\n",
    "def U_SU4(params, wires): # 15 params\n",
    "    qml.U3(params[0], params[1], params[2], wires=wires[0])\n",
    "    qml.U3(params[3], params[4], params[5], wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[0], wires[1]])\n",
    "    qml.RY(params[6], wires=wires[0])\n",
    "    qml.RZ(params[7], wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[1], wires[0]])\n",
    "    qml.RY(params[8], wires=wires[0])\n",
    "    qml.CNOT(wires=[wires[0], wires[1]])\n",
    "    qml.U3(params[9], params[10], params[11], wires=wires[0])\n",
    "    qml.U3(params[12], params[13], params[14], wires=wires[1])\n",
    "\n",
    "# Pooling Layer\n",
    "\n",
    "def Pooling_ansatz1(params, wires): #2 params\n",
    "    qml.CRZ(params[0], wires=[wires[0], wires[1]])\n",
    "    qml.PauliX(wires=wires[0])\n",
    "    qml.CRX(params[1], wires=[wires[0], wires[1]])\n",
    "\n",
    "def Pooling_ansatz2(wires): #0 params\n",
    "    qml.CRZ(wires=[wires[0], wires[1]])\n",
    "\n",
    "def Pooling_ansatz3(*params, wires): #3 params\n",
    "    qml.CRot(*params, wires=[wires[0], wires[1]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#ancilla interactions layer J_OUR\n",
    "def Ancilla_ansatz1(params, wires): #0 params\n",
    "    qml.CNOT(wires=[wires[3],wires[0]])\n",
    "    qml.CNOT(wires=[wires[0],wires[1]])\n",
    "    qml.CNOT(wires=[wires[1],wires[2]])\n",
    "    qml.CNOT(wires=[wires[2],wires[3]])\n",
    "    qml.CNOT(wires=[wires[1],wires[4]])\n",
    "    qml.CNOT(wires=[wires[2],wires[5]])\n",
    "\n",
    "    qml.Rot(params[0], params[1], params[2], wires=4)\n",
    "    qml.Rot(params[3], params[4], params[5], wires=5)\n",
    "\n",
    "\n",
    "\n",
    "def Ancilla_toffoli_ansantz(params, wires):\n",
    "    qml.Toffoli(wires=[wires[1],wires[2],wires[3]])\n",
    "    qml.Toffoli(wires=[wires[0],wires[1],wires[2]])\n",
    "\n",
    "    qml.RX(params[0], wires[0])\n",
    "    qml.RX(params[1], wires[1])\n",
    "    qml.RX(params[2], wires[2])\n",
    "    qml.RX(params[3], wires[3])\n",
    "\n",
    "    qml.Toffoli(wires=[wires[0],wires[3],wires[1]])\n",
    "    qml.RY(params[4], wires[0])\n",
    "    qml.RY(params[5], wires[1])\n",
    "    qml.RY(params[6], wires[2])\n",
    "    qml.RY(params[7], wires[3])\n",
    "\n",
    "    qml.Toffoli(wires=[wires[3],wires[2],wires[0]])\n",
    "    \n",
    "    qml.RZ(params[8], wires[0])\n",
    "    qml.RZ(params[9], wires[1])\n",
    "    qml.RZ(params[10], wires[2])\n",
    "    qml.RZ(params[11], wires[3])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def Ancilla_toffoli_ansantz_paramless(wires):\n",
    "\n",
    "    qml.Toffoli(wires=[wires[1],wires[2],wires[3]])\n",
    "    qml.Toffoli(wires=[wires[0],wires[1],wires[2]])\n",
    "    qml.Toffoli(wires=[wires[0],wires[3],wires[1]])\n",
    "    qml.Toffoli(wires=[wires[3],wires[2],wires[0]])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data embedding function\n",
    "\n",
    "def data_embedding(X, embedding_type='Amplitude'):\n",
    "    if embedding_type == 'Amplitude':\n",
    "        AmplitudeEmbedding(X, wires=range(8), normalize=True)\n",
    "    elif embedding_type == 'Angle':\n",
    "        AngleEmbedding(X, wires=range(8), rotation='Y')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional layers using unitaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantum Circuits for Convolutional layers\n",
    "def conv_layer1(U, params):\n",
    "    U(params, wires=[0, 7])\n",
    "    for i in range(0, 8, 2):\n",
    "        U(params, wires=[i, i + 1])\n",
    "    for i in range(1, 7, 2):\n",
    "        U(params, wires=[i, i + 1])\n",
    "def conv_layer2(U, params):\n",
    "    U(params, wires=[0, 6])\n",
    "    U(params, wires=[0, 2])\n",
    "    U(params, wires=[4, 6])\n",
    "    U(params, wires=[2, 4])\n",
    "def conv_layer3(U, params):\n",
    "    U(params, wires=[0,4])\n",
    "\n",
    "# Quantum Circuits for Pooling layers\n",
    "def pooling_layer1(V, params):\n",
    "    for i in range(0, 8, 2):\n",
    "        V(params, wires=[i + 1, i])\n",
    "def pooling_layer2(V, params):\n",
    "    V(params, wires=[2,0])\n",
    "    V(params, wires=[6,4])\n",
    "def pooling_layer3(V, params):\n",
    "    V(params, wires=[0,4])\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "    \n",
    "def ancilla_interaction_layer(A, params):\n",
    "    A(params, wires=[0, 2, 4, 6, 8, 9])\n",
    "\n",
    "def ancilla_toffoli_interaction_layer(A, params):\n",
    "    A(params, wires=[0, 2, 4, 6])\n",
    "\n",
    "def ancilla_toffoli_interaction_layer_paramless(A):\n",
    "    A(wires=[0, 2, 4, 6])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def QCNN_our_structure(U, params, U_params): # number of weights is 15*2 + 2 + 8 = U_params, params =  weights\n",
    "    \n",
    "    param1 = params[0:U_params]\n",
    "    param2 = params[U_params: 2 * U_params]\n",
    "    param3 = params[2 * U_params: 2*U_params + 2]\n",
    "    param4 = params[2*U_params + 2: 2*U_params + 8]\n",
    "    \n",
    "    # Pooling Ansatz1 is used by default\n",
    "    conv_layer1(U, param1)\n",
    "    pooling_layer1(Pooling_ansatz1, param3)\n",
    "    conv_layer2(U, param2)\n",
    "    ancilla_interaction_layer(Ancilla_ansatz1, param4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def QCNN_our_structure_toffoli(U, params, U_params): # number of weights is 15*2 + 2 + 8 = U_params, params =  weights\n",
    "\n",
    "    param1 = params[0:U_params]\n",
    "    param2 = params[U_params: 2 * U_params]\n",
    "    param3 = params[2 * U_params: 2*U_params + 2]\n",
    "    param4 = params[2*U_params + 2: 2*U_params + 14]\n",
    "    param5 = params[2*U_params + 14: 2*U_params + 20]\n",
    "    \n",
    "\n",
    "    conv_layer1(U, param1)\n",
    "    pooling_layer1(Pooling_ansatz1, param3)\n",
    "    ancilla_toffoli_interaction_layer_paramless(Ancilla_toffoli_ansantz_paramless)\n",
    "    conv_layer2(U, param2)\n",
    "    ancilla_toffoli_interaction_layer(Ancilla_toffoli_ansantz, param4)\n",
    "    ancilla_interaction_layer(Ancilla_ansatz1, param5)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device('default.qubit', wires = 10) \n",
    "@qml.qnode(dev)\n",
    "def QCNN(X, params, U, U_params, embedding_type='Amplitude', cost_fn='cross_entropy'):\n",
    "\n",
    "    # Data Embedding\n",
    "    data_embedding(X, embedding_type=embedding_type)\n",
    "\n",
    "    # Quantum Convolutional Neural Network\n",
    "    if U == 'U_6':\n",
    "        QCNN_our_structure_toffoli(U_6, params, U_params)\n",
    "    elif U == 'U_SU4':\n",
    "        QCNN_our_structure_toffoli(U_SU4, params, U_params)\n",
    "    else:\n",
    "        print(\"Invalid Unitary Ansatze\")\n",
    "        return False\n",
    "\n",
    "\n",
    "    if cost_fn == 'cross_entropy':\n",
    "        return qml.expval(qml.PauliZ(8)), qml.expval(qml.PauliZ(9))\n",
    "    else :\n",
    "        print(\"Invalid Cost Function\")\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost and loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost and loss functions, must be changed to one hot encoding\n",
    "\n",
    "def cross_entropy(labels, predictions): \n",
    "    loss = 0\n",
    "    for i, j in zip(labels, predictions):\n",
    "        loss = loss + i*np.log(j)\n",
    "        #print(loss)\n",
    "    return -1*loss\n",
    "\n",
    "def cost(params, X, Y, U, U_params, embedding_type, circuit, cost_fn): \n",
    "    if circuit == 'QCNN':\n",
    "        loss = 0\n",
    "        for l , x in zip(Y, X):\n",
    "\n",
    "            predictions = QCNN(x, params, U, U_params, embedding_type, cost_fn=cost_fn)\n",
    "            predictions = softmax(predictions)\n",
    "            loss = loss + cross_entropy(l, predictions)\n",
    "        loss = loss/len(Y)\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid Cost Function\")\n",
    "        return False\n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training params and training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Circuit training parameters\n",
    "steps = 501\n",
    "learning_rate = 0.05\n",
    "batch_size = 50\n",
    "\n",
    "def circuit_training(X_train, Y_train, X_test, Y_test, U, U_params, embedding_type, circuit, cost_fn, binary):\n",
    "    if circuit == 'QCNN':\n",
    "        total_params = U_params * 2 + 20  # J changes for last gate on ancilla + toffoli \n",
    "\n",
    "    params = np.random.randn(total_params, requires_grad=True)\n",
    "    opt = qml.NesterovMomentumOptimizer(stepsize=learning_rate)\n",
    "    loss_history = []\n",
    "    acc_history = []\n",
    "\n",
    "    f = open('Result/recording.txt', 'a')\n",
    "    f.write(\"initial params: \" + str(params))\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.close()\n",
    "\n",
    "    for it in range(steps):\n",
    "        f = open('Result/recording.txt', 'a')\n",
    "        batch_index = np.random.randint(0, len(X_train), (batch_size,))\n",
    "        X_batch = X_train[batch_index]\n",
    "        Y_batch = Y_train[batch_index]\n",
    "\n",
    "        params, cost_new = opt.step_and_cost(lambda v: cost(v, X_batch, Y_batch, U, U_params, embedding_type, circuit, cost_fn),\n",
    "                                                     params)\n",
    "        loss_history.append(cost_new)\n",
    "\n",
    "      \n",
    "        if it % 10 == 0:           \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for l, x in zip(Y_test, X_test):\n",
    "                act_label = np.argmax(l) \n",
    "                pred_result = softmax(QCNN(x, params, U, U_params, embedding_type, cost_fn))\n",
    "                pred_label = np.argmax(pred_result) \n",
    "                if(act_label == pred_label):\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "            accuracy = (correct/total)\n",
    "            acc_history.append(accuracy)\n",
    "            print(\"iteration: \", it, \" cost: \", cost_new, \"accuracy: \", str(accuracy))\n",
    "            f.write(\"iteration:\" + str(it) + \" cost:\" + str(cost_new) + \" \"   \" accuracy \" + str(accuracy))\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "            if accuracy > 0.900:\n",
    "                f.write(\"params: \" + str(params) + \"\\n\\n\")\n",
    "            \n",
    "            # if (it < 151) and (it % 50 ==0):\n",
    "            #     opt.stepsize =  learning_rate/2 \n",
    "                \n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"acc history: \" + str(acc_history))        \n",
    "    f.close()\n",
    "\n",
    "            #print(\"\\n \\n\")\n",
    "    return loss_history, params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loads and processes, Prep Xtrain Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepping Xtrain Ytrain, must be one hot coded \n",
    "\n",
    "def data_load_and_process(dataset, classes=[0, 1], feature_reduction='resize256', binary=True):\n",
    "    if dataset == 'fashion_mnist':\n",
    "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "        #print('loaded fashion mnnist')\n",
    "\n",
    "    elif dataset == 'mnist':\n",
    "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    x_train, x_test = x_train[..., np.newaxis] / 255.0, x_test[..., np.newaxis] / 255.0  # normalize the data\n",
    "\n",
    "    x_train_filter_01 = np.where((y_train == classes[0]) | (y_train == classes[1]))\n",
    "    x_test_filter_01 = np.where((y_test == classes[0]) | (y_test == classes[1]))\n",
    "\n",
    "    X_train, X_test = x_train[x_train_filter_01], x_test[x_test_filter_01]\n",
    "    Y_train, Y_test = y_train[x_train_filter_01], y_test[x_test_filter_01]\n",
    "\n",
    "\n",
    "    if binary == False:\n",
    "        Y_train = [1 if y == classes[0] else 0 for y in Y_train]\n",
    "        Y_test = [1 if y == classes[0] else 0 for y in Y_test]\n",
    "    elif binary == True:\n",
    "        Y_train = [1 if y == classes[0] else -1 for y in Y_train]\n",
    "        Y_test = [1 if y == classes[0] else -1 for y in Y_test]\n",
    "    \n",
    "    if feature_reduction == 'resize256':\n",
    "    \n",
    "        X_train = tf.image.resize(X_train[:], (256, 1)).numpy()\n",
    "        X_test = tf.image.resize(X_test[:], (256, 1)).numpy()\n",
    "        X_train, X_test = tf.squeeze(X_train).numpy(), tf.squeeze(X_test).numpy()\n",
    "\n",
    "      \n",
    "        Y_train = tf.keras.utils.to_categorical(Y_train, num_classes=2)\n",
    "        Y_test = tf.keras.utils.to_categorical(Y_test, num_classes=2)   \n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "    elif feature_reduction == 'autoencoder8':\n",
    "    \n",
    "        latent_dim = 8\n",
    "        \n",
    "\n",
    "        class Autoencoder(Model):\n",
    "            def __init__(self, latent_dim):\n",
    "                super(Autoencoder, self).__init__()\n",
    "                self.latent_dim = latent_dim\n",
    "                self.encoder = tf.keras.Sequential([\n",
    "                    layers.Flatten(),\n",
    "                    layers.Dense(latent_dim, activation='relu'),\n",
    "                ])\n",
    "                self.decoder = tf.keras.Sequential([\n",
    "                    layers.Dense(784, activation='sigmoid'),\n",
    "                    layers.Reshape((28, 28))\n",
    "                ])\n",
    "\n",
    "            def call(self, x):\n",
    "                encoded = self.encoder(x)\n",
    "                decoded = self.decoder(encoded)\n",
    "                return decoded\n",
    "\n",
    "        autoencoder = Autoencoder(latent_dim)\n",
    "\n",
    "        autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "        autoencoder.fit(X_train, X_train,\n",
    "                        epochs=10,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(X_test, X_test))\n",
    "\n",
    "        X_train, X_test = autoencoder.encoder(X_train).numpy(), autoencoder.encoder(X_test).numpy()\n",
    "\n",
    "        # Rescale for Angle Embedding\n",
    "    \n",
    "        if feature_reduction == 'autoencoder8':\n",
    "            X_train, X_test = (X_train - X_train.min()) * (np.pi / (X_train.max() - X_train.min())), \\\n",
    "                              (X_test - X_test.min()) * (np.pi / (X_test.max() - X_test.min()))\n",
    "                              \n",
    "        Y_train = tf.keras.utils.to_categorical(Y_train, num_classes=2)\n",
    "        Y_test = tf.keras.utils.to_categorical(Y_test, num_classes=2)\n",
    "    \n",
    "\n",
    "        return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecoding to Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts encoding to embedding\n",
    "\n",
    "def Encoding_to_Embedding(Encoding):\n",
    "    #Amplitude Embedding / Angle Embedding\n",
    "    print(type(Encoding))\n",
    "    if Encoding == 'resize256':\n",
    "        Embedding = 'Amplitude'\n",
    "        #print(\"kano dhuktese na bhai\")\n",
    "    elif Encoding == 'autoencoder8':\n",
    "        Embedding = 'Angle'\n",
    "    else :\n",
    "        print(\"Inavlid embedding\")\n",
    "    return Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function(dataset, classes, Unitaries, U_num_params, Encodings, circuit, cost_fn, binary=True):\n",
    "\n",
    "    f = open('Result/result_US.txt', 'a')\n",
    "    \n",
    "    U = Unitaries\n",
    "    U_params = U_num_params\n",
    "    Encoding = Encodings\n",
    "    Embedding = Encoding_to_Embedding(Encoding)\n",
    "\n",
    "    feature_reduction = Encoding\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = data_load_and_process(dataset, classes=classes,\n",
    "                                                                feature_reduction=Encoding, binary=binary)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"Loss History for \" + circuit + \" circuits, \" + U + \" \" + Encoding + \" with \" + cost_fn)\n",
    "    loss_history, trained_params = circuit_training(X_train, Y_train, X_test, Y_test, U, U_params, Embedding, circuit, cost_fn, binary) #R_OUR added X_test, Y_test, binary\n",
    "\n",
    "\n",
    "\n",
    "    f.write(\"Loss History for \" + circuit + \" circuits, \" + U + \" \" + Encoding + \" with \" + cost_fn)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(str(loss_history))\n",
    "    f.write(\"\\n\")\n",
    "    #f.write(\"Accuracy for \" + U + \" \" + Encoding + \" :\" + str(accuracy))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    return loss_history, trained_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally training and printing the test accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unitaries = 'U_SU4' #usu4 is ansatz 1 and usu6 is ansatz 2. The others were used for testing, and have been taken from Hur et. al.\n",
    "\n",
    "U_num_params = 15\n",
    "Encodings = 'autoencoder8'\n",
    "dataset = 'fashion_mnist'\n",
    "classes = [0,1]\n",
    "binary = False\n",
    "cost_fn = 'cross_entropy'\n",
    "\n",
    "\n",
    "loss_history, trained_params = main_function(dataset, classes, Unitaries, U_num_params, Encodings, circuit='QCNN', cost_fn=cost_fn, binary=binary)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trained_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Result/recording.txt', 'a')\n",
    "f.write(\"\\n\")\n",
    "f.write(\"loss history: \" + str(loss_history))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7c6b30c38655ebc7b7deff9f74590182d27886647dc972f142a5f894f192e5f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
